# Distributed Cache Service

**January 2025 â€“ March 2025**

*   Developed a distributed service capable of handling 10,000+ concurrent requests with sub-millisecond response times.
*   Implemented advanced algorithms for data partitioning across nodes, ensuring balanced data distribution and fault tolerance.
*   Created a comprehensive monitoring system to track cache performance metrics, latency, and system health.

**Technologies Planned:** C, Java, Spring Boot, Docker, Kubernetes 